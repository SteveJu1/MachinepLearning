### 机器学习实战学习笔记
环境与客体统称为“模式  
在90年代初是用数据（可以通过廉价劳动力采集获得）去替换专家  
#### 机器学习应用
搜索引擎: 判断哪个结果更适合你（也判断哪个广告更适合你）   
自动识别寄送贺卡的地址  
申请贷款: 通过你最近的金融活动信息进行综合评定，决定你是否合格。  
#### 主要任务：
***
分类（classification）：二分类，多分类。数值是离散的如1，2，3（将一些未知类别的数据分到 现在已知的类别）  
评判分类效果好坏的三个指标 ： 正确率，召回率，F值  
算法有 ：K-近邻算法  线性回归  决策树

***
回归（regression）：主要用于预测连续的（ 0~100）评判分类效果好坏指标：误差
还有一种：如输入图片--输入文字  
规则集：【例如：数学成绩大于90分为优秀】

#### 强化学习:让算法自己去尝试所有的可能行动，只评价结果的好坏  
如AlphaGo采用的是监督学习（看棋谱）和强化学习（自己和自己下，最后给出谁赢了就行，赢的会继续使用之前的模型参数）  

Underfitting  模型没有很好地捕捉到数据特征，不能够很好地拟合数据  
过拟合（Overfitting）：一些训练样本自身的特性当做了所有潜在样本都有的一般性质，导致泛化能力下降  

#### 模型指标 
正确率accuracy：正确的信息 /提取出的
召回率:正确的 / 样本中的所有信息
F值：正确率和召回率的调和平均值 
特征处理 ：
（1）特征清洗
（2） 预处理：   归一化，离散化，缺失值 ， 降维
数据变化:log 、指数 、box-cox 
L1范数：为x向量各个元素绝对值之和；  
L2范数：为x向量各个元素平方和的开方  
L1范数和L2范数很常见，主要用在损失函数中起到一个限制模型参数复杂度的作用  
特征分解是即将矩阵分解成一组特征向量和特征值

#### 夹角余弦
夹角余弦用来衡量两个向量方向的差异，取值范围为[-1,1]  
夹角余弦越大，表示两个向量的夹角越小；当两个向量的方向重合时，夹角余弦取最大值1；当两个向量的方向完全相反时，夹角余弦取最小值-1  

