## 模型评估
* 准确率（Accuracy）是指分类正确的样本占总样本个数的比例（有负样本）,
缺点：比如，当负样本占99%时，分类器把所有样本都预测为负样本也可以获得99%的准确率。   
所以， 当不同类别的样本比例非常不均衡时， 占比大的类别往往成为影响准确率的最主要因素。为了解决
这个问题， 可以使用更为有效的平均准确率（每个类别下的样本准确率的算术平均） 作为模型评估的指标。
* 精确率（Precision） 是指分类正确的正样本个数占分类器判定为正样本的样本个数的比例。  
召回率（Recall）是指分类正确的正样本个数占真正的正样本个数的比例。  
___
Precision值和Recall值是既矛盾又统一的两个指标， 为了提高Precision值， 分类器需要尽量在“更有把握”时才把样本预测为正样本， 但此时往往会因为过于保
守而漏掉很多“没有把握”的正样本， 导致Recall值降低
___
P-R（PrecisionRecall） 曲线 F1 score是精准率和召回率的调和平均值
比RMSE的鲁棒性更好的指标， 比如平均绝对百分比误差,把每个点的误差进行了归一化

* ROC曲线是Receiver Operating Characteristic Curve的简称， 中文名为“受试者工作特征曲线”。 
ROC曲线的横坐标为假阳性率（False Positive Rate， FPR） ； 纵坐标为真阳性率
ROC曲线能够尽量降低不同测试集带来的干扰， 更加客观地衡量模型本身的性能  
___
在机器学习问题中， 通常将特征表示为向量的形式， 所以在分析两个特征向量之间的相似性时， 常使用余弦相似度来表示。 
余弦相似度的取值范围是[−1,1]，相同的两个向量之间的相似度为1。 如果希望得到类似于距离的表示， 将1减去余弦相似度即为余弦距离。 
因此， 余弦距离的取值范围为[0,2]， 相同的两个向量余弦距离为0。
___
#### 问题1 结合你的学习和研究经历， 探讨为什么在一些场景中要使用余弦相似度而不是欧氏距离？
余弦相似度定义为即两个向量夹角的余弦， 关注的是向量之间的角度关系， 并不关心它们的绝对大小， 其取值范围是[−1,1]。  
当一对文本相似度的长度差距很大、 但内容相近时， 如果使用词频或词向量作为特征， 它们在特征空间中的的欧氏距离通常很大  
而如果使用余弦相似度的话， 它们之间的夹角可能很小， 因而相似度高。

#### 问题 在对模型进行过充分的离线评估之后， 为什么还要进行在线A/B测试？
（1） 离线评估无法完全消除模型过拟合的影响， 因此， 得出的离线评估结果无法完全替代线上评估结果。
（2） 离线评估无法完全还原线上的工程环境。 线上环境的延迟、 数据丢失、 标签数据缺失等情况。 
#### 如何进行线上A/B测试？
进行A/B测试的主要手段是进行用户分桶， 即将用户分成实验组和对照组， 对实验组的用户施以新模型， 对对照组的用户施以旧模型。

#### 在模型评估过程中， 有哪些主要的验证方法， 它们的优缺点是什么?
* Holdout检验
Holdout 检验是最简单也是最直接的验证方法， 它将原始的样本集合随机划分成训练集和验证集两部分。 
比方说， 对于一个点击率预测模型， 我们把样本按照70%～30% 的比例分成两部分， 70% 的样本用于模型训练； 
30% 的样本用于模型验证， 包括绘制ROC曲线、 计算精确率和召回率等指标来评估模型性能。
* 交叉检验
k-fold交叉验证： 首先将全部样本划分成k个大小相等的样本子集；依次遍历这k个子集， 每次把当前子集作为验证集， 其余所有子集作为训练集， 进行模型的
训练和评估； 最后把k次评估指标的平均值作为最终的评估指标。 在实际实验中， k经常取10。
### 超参数有哪些调优方法？
为了进行超参数调优， 我们一般会采用网格搜索、 随机搜索、 贝叶斯优化等算法。 
在具体介绍算法之前， 需要明确超参数搜索算法一般包括哪几个要素。 一是目标函数， 即算法需要最大化/最小化的目标；   
二是搜索范围， 一般通过上限和下限来确定； 三是算法的其他参数， 如搜索步长。
* 网格搜索
它通过查找搜索范围内的所有的点来确定最优值。 如果采用较大的搜索范围以及较小的步长， 网格
搜索有很大概率找到全局最优值。 然而， 这种搜索方案十分消耗计算资源和时间， 特别是需要调优的超参数比较多的时候。
*  贝叶斯优化算法
网格搜索和随机搜索在测试一个新点时， 会忽略前一个点的信息；而贝叶斯优化算法则充分利用了之前的信息。 贝叶斯优化算法通过对目标函数形
状进行学习， 找到使目标函数向全局最优值提升的参数。 
#### 过拟合和欠拟合具体是指什么现象？
```
过拟合:在训练集上的表现很好， 但在测试集和新数据上的表现较差。
从数据入手， 获得更多的训练数据。  
降低模型复杂度。
正则化方法
成学习方法
```
```
欠拟合:模型在训练和预测时表现都不好
添加新特征。
增加模型复杂度
减小正则化系数
```
